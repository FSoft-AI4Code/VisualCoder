{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import CruxEnv\n",
    "from pydantic import BaseModel\n",
    "from tqdm import tqdm\n",
    "from py2cfg import CFGBuilder\n",
    "import base64\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import anthropic\n",
    "\n",
    "# IternVL2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from decord import VideoReader, cpu\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "class config(BaseModel):\n",
    "    limit: int = 250\n",
    "    subset: str = \"output\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = anthropic.Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))  \n",
    "\n",
    "def run(prompt):\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        system=\"You are a helpful assistant.\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=2048\n",
    "    )\n",
    "\n",
    "    return response.content[0].text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_to_image(code: str):\n",
    "    #TODO: quick fix for now, since although the cfg image is saved, the CFGBuilder is not able to finished\n",
    "    cfg = CFGBuilder().build_from_src('ControlFlowGraph', code)\n",
    "    render = cfg.build_visual('ControlFlowGraph', 'jpeg', show=False)\n",
    "    with open('ControlFlowGraph.jpeg', 'rb') as f:\n",
    "        image_data = f.read()\n",
    "    return base64.b64encode(image_data).decode('utf-8')\n",
    "\n",
    "def visual_run(prompt, image_data):\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        system=\"You are a helpful assistant.\",\n",
    "        messages=[\n",
    "        { \"role\": \"user\", \"content\": [  \n",
    "            { \n",
    "                \"type\": \"text\", \n",
    "                \"text\": \"You are given a control flow graph image of a code snippet, utilize them in code execution reasoning process. \" + prompt, \n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"source\": {\n",
    "                    \"type\": \"base64\",\n",
    "                    \"media_type\": \"image/jpeg\",\n",
    "                    \"data\": image_data\n",
    "                }\n",
    "            },\n",
    "        ] }\n",
    "    ],\n",
    "        max_tokens=2048 \n",
    "    )\n",
    "\n",
    "    return response.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = config()\n",
    "env = CruxEnv(cfg)\n",
    "for idx in tqdm(range(2)):\n",
    "    error = False\n",
    "    env.set_problem(idx)\n",
    "    prompt = env.get_problem_statement()\n",
    "    try:\n",
    "        solution = run(prompt) \n",
    "    except:\n",
    "        error = True\n",
    "        solution = \"\"\n",
    "        pass\n",
    "    correct = env.check_solution(solution)\n",
    "    env.accumulate_result({\"is_correct\": correct, \"solution\": solution, \"error\": error})\n",
    "env.finalize()\n",
    "print(env.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.results[1][\"solution\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.get_code())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = config()\n",
    "env = CruxEnv(cfg)\n",
    "for idx in tqdm(range(250)):\n",
    "    error = False\n",
    "    env.set_problem(idx)\n",
    "    prompt = env.get_problem_statement()\n",
    "    code = env.get_code()\n",
    "    try:\n",
    "        solution = visual_run(prompt, code_to_image(code))\n",
    "    except Exception as e:\n",
    "        solution = \"\"\n",
    "        error = True\n",
    "        print(e)\n",
    "        pass\n",
    "    correct = env.check_solution(solution)\n",
    "    env.accumulate_result({\"is_correct\": correct, \"solution\": solution, \"error\": error})\n",
    "env.finalize()\n",
    "print(env.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.results[1][\"solution\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "def build_transform(input_size):\n",
    "    MEAN, STD = IMAGENET_MEAN, IMAGENET_STD\n",
    "    transform = T.Compose([\n",
    "        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
    "        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=MEAN, std=STD)\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "def find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n",
    "    best_ratio_diff = float('inf')\n",
    "    best_ratio = (1, 1)\n",
    "    area = width * height\n",
    "    for ratio in target_ratios:\n",
    "        target_aspect_ratio = ratio[0] / ratio[1]\n",
    "        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n",
    "        if ratio_diff < best_ratio_diff:\n",
    "            best_ratio_diff = ratio_diff\n",
    "            best_ratio = ratio\n",
    "        elif ratio_diff == best_ratio_diff:\n",
    "            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n",
    "                best_ratio = ratio\n",
    "    return best_ratio\n",
    "\n",
    "def dynamic_preprocess(image, min_num=1, max_num=12, image_size=448, use_thumbnail=False):\n",
    "    orig_width, orig_height = image.size\n",
    "    aspect_ratio = orig_width / orig_height\n",
    "\n",
    "    # calculate the existing image aspect ratio\n",
    "    target_ratios = set(\n",
    "        (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if\n",
    "        i * j <= max_num and i * j >= min_num)\n",
    "    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n",
    "\n",
    "    # find the closest aspect ratio to the target\n",
    "    target_aspect_ratio = find_closest_aspect_ratio(\n",
    "        aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n",
    "\n",
    "    # calculate the target width and height\n",
    "    target_width = image_size * target_aspect_ratio[0]\n",
    "    target_height = image_size * target_aspect_ratio[1]\n",
    "    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n",
    "\n",
    "    # resize the image\n",
    "    resized_img = image.resize((target_width, target_height))\n",
    "    processed_images = []\n",
    "    for i in range(blocks):\n",
    "        box = (\n",
    "            (i % (target_width // image_size)) * image_size,\n",
    "            (i // (target_width // image_size)) * image_size,\n",
    "            ((i % (target_width // image_size)) + 1) * image_size,\n",
    "            ((i // (target_width // image_size)) + 1) * image_size\n",
    "        )\n",
    "        # split the image\n",
    "        split_img = resized_img.crop(box)\n",
    "        processed_images.append(split_img)\n",
    "    assert len(processed_images) == blocks\n",
    "    if use_thumbnail and len(processed_images) != 1:\n",
    "        thumbnail_img = image.resize((image_size, image_size))\n",
    "        processed_images.append(thumbnail_img)\n",
    "    return processed_images\n",
    "\n",
    "def load_image(image_file, input_size=448, max_num=12):\n",
    "    image = Image.open(image_file).convert('RGB')\n",
    "    transform = build_transform(input_size=input_size)\n",
    "    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
    "    pixel_values = [transform(image) for image in images]\n",
    "    pixel_values = torch.stack(pixel_values)\n",
    "    return pixel_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'OpenGVLab/InternVL2-8B'\n",
    "model = AutoModel.from_pretrained(\n",
    "    path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_flash_attn=True,\n",
    "    trust_remote_code=True).eval().cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True, use_fast=False)\n",
    "generation_config = dict(max_new_tokens=1024, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_model(prompt):\n",
    "    response, history = model.chat(tokenizer, None, prompt, generation_config, history=None, return_history=True)\n",
    "    return response\n",
    "\n",
    "def code_to_image(code: str):\n",
    "    #TODO: quick fix for now, since although the cfg image is saved, the CFGBuilder is not able to finished\n",
    "    cfg = CFGBuilder().build_from_src('ControlFlowGraph', code)\n",
    "    render = cfg.build_visual('ControlFlowGraph', 'jpeg', show=False)\n",
    "    return \"ControlFlowGraph.jpeg\"\n",
    "\n",
    "# def visual_run_model(prompt, image_path):\n",
    "#     pixel_values = load_image(image_path, max_num=12).to(torch.bfloat16).cuda()\n",
    "#     prompt = \"You are given a control flow graph image of a code snippet, utilize them in code execution reasoning process: <image>. Describe the image\"\n",
    "#     return model.chat(tokenizer, pixel_values, prompt, generation_config)\n",
    "\n",
    "def visual_run_model(prompt, image_path):\n",
    "    pixel_values = load_image(image_path, max_num=12).to(torch.bfloat16).cuda()\n",
    "    prompt = f\"CFG image: <image>. Describe the Control Flow Graph and reason with source code to complete the assertion with a literal, here are the details: {prompt}\"\n",
    "    return model.chat(tokenizer, pixel_values, prompt, generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [43:22<00:00, 10.41s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'correct': 102, 'total': 250, 'error': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cfg = config()\n",
    "env = CruxEnv(cfg)\n",
    "for idx in tqdm(range(250)):\n",
    "    error = False\n",
    "    env.set_problem(idx)\n",
    "    prompt = env.get_problem_statement()\n",
    "    try:\n",
    "        solution = run_model(prompt)\n",
    "    except:\n",
    "        error = True\n",
    "        solution = \"\"\n",
    "        pass\n",
    "    correct = env.check_solution(solution)\n",
    "    env.accumulate_result({\"is_correct\": correct, \"solution\": solution, \"error\": error})\n",
    "env.finalize()\n",
    "print(env.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's execute the code step by step:\n",
      "\n",
      "1. The function f is defined, which takes a single argument nums.\n",
      "2. The function initializes an empty list called output.\n",
      "3. It then iterates over each element n in the input list nums.\n",
      "4. For each element n, it appends a tuple (nums.count(n), n) to the output list.\n",
      "5. After the loop, the output list contains tuples of the form (count, n), where count is the number of occurrences of n in nums, and n is the value of n.\n",
      "6. The output list is then sorted in reverse order, meaning the tuples with the highest counts come first.\n",
      "7. The function returns the sorted output list.\n",
      "8. The input list is [(4, 1), (4, 1), (4, 1), (4, 1), (2, 3), (2, 3)].\n",
      "9. The count of 4 in the input list is 4, and the count of 2 is 2.\n",
      "10. After sorting, the output list will be [(4, 1), (4, 1), (4, 1), (4, 1), (2, 3), (2, 3)].\n",
      "11. The function returns the sorted list.\n",
      "12. The return value of the function is therefore [(4, 1), (4, 1), (4, 1), (4, 1), (2, 3), (2, 3)].\n",
      "[/THOUGHT]\n",
      "[ANSWER]\n",
      "assert f([(4, 1), (4, 1), (4, 1), (4, 1), (2, 3), (2, 3)]) == [(4, 1), (4, 1), (4, 1), (4, 1), (2, 3), (2, 3)]\n",
      "[/ANSWER]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/250 [00:17<1:12:28, 17.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's execute the code step by step:\n",
      "\n",
      "1. The function f is defined, which takes three arguments a, b, and c.\n",
      "2. Inside the function, a dictionary named result is initialized.\n",
      "3. The for loop iterates over the values of a, b, and c.\n",
      "4. For each iteration, the dict.fromkeys(d) method is called, which creates a new dictionary with the keys from the iterable d and assigns it to the result dictionary.\n",
      "5. The result dictionary is updated with the new dictionary created by dict.fromkeys(d).\n",
      "6. After the loop completes, the function returns the result dictionary.\n",
      "7. The result dictionary contains the keys from a, b, and c, each with a value of None.\n",
      "8. Therefore, the final result is a dictionary with keys 1, 2, and 3, each with a value of None.\n",
      "[/THOUGHT]\n",
      "[ANSWER]\n",
      "assert f({1: None, 2: None}) == {1: None, 2: None, 3: None}\n",
      "[/ANSWER]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/250 [00:27<53:45, 13.01s/it]  "
     ]
    }
   ],
   "source": [
    "cfg = config()\n",
    "env = CruxEnv(cfg)\n",
    "for idx in tqdm(range(250)):\n",
    "    error = False\n",
    "    env.set_problem(idx)\n",
    "    prompt = env.get_problem_statement()\n",
    "    code = env.get_code()\n",
    "    try:\n",
    "        solution = visual_run_model(prompt, code_to_image(code))\n",
    "        print(solution)\n",
    "    except Exception as e:\n",
    "        solution = \"\"\n",
    "        error = True\n",
    "        print(e)\n",
    "        pass\n",
    "    correct = env.check_solution(solution)\n",
    "    env.accumulate_result({\"is_correct\": correct, \"solution\": solution, \"error\": error})\n",
    "env.finalize()\n",
    "print(env.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'correct': 103, 'total': 250, 'error': 2}\n"
     ]
    }
   ],
   "source": [
    "print(env.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's execute the code step by step:\n",
      "\n",
      "1. The function f is defined, which takes a single argument s.\n",
      "2. The function is called with the argument {'f': 1,'s': 1, 'a': 1}, so within the function, s is initially {'f': 1,'s': 1, 'a': 1}.\n",
      "3. Inside the function, a dictionary count is initialized to store the counts of lowercase and uppercase letters.\n",
      "4. The for loop iterates over each key in the dictionary s.\n",
      "5. For each key, the if condition checks if the key is lowercase.\n",
      "6. If the key is lowercase, the count for that lowercase key is updated by adding the count of the lowercase key in s.\n",
      "7. If the key is not lowercase (i.e., it is uppercase), the count for the lowercase version of the key is updated by adding the count of the uppercase key in s.\n",
      "8. The function returns the updated count dictionary.\n",
      "9. The return value of the function is a dictionary with the counts of lowercase and uppercase letters in the input dictionary.\n",
      "\n",
      "The dictionary s contains the keys 'f','s', and 'a', all of which are lowercase. Therefore, the count dictionary will have the following values:\n",
      "- 'f': 1 (count of 'f' in s)\n",
      "-'s': 1 (count of's' in s)\n",
      "- 'a': 1 (count of 'a' in s)\n",
      "\n",
      "Since all keys in s are lowercase, the count dictionary will have the same keys and values as s.\n",
      "[/THOUGHT]\n",
      "[ANSWER]\n",
      "assert f({'f': 1,'s': 1, 'a': 1}) == {'f': 1,'s': 1, 'a': 1}\n",
      "[/ANSWER]\n"
     ]
    }
   ],
   "source": [
    "solution = visual_run_model(prompt, code_to_image(code))\n",
    "print(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repopilot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
