{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tasks.execution.crux_execution import CruxEnv\n",
    "from pydantic import BaseModel\n",
    "from tqdm import tqdm\n",
    "from py2cfg import CFGBuilder\n",
    "import base64\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import anthropic\n",
    "\n",
    "# IternVL2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from decord import VideoReader, cpu\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import time\n",
    "\n",
    "class config(BaseModel):\n",
    "    limit: int = 250\n",
    "    subset: str = \"input\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = anthropic.Anthropic(api_key=\"\")  \n",
    "def run(prompt):\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        system=\"You are a helpful assistant.\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=2048\n",
    "    )\n",
    "\n",
    "    return response.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_to_image(code: str, path: str):\n",
    "    with open(path, 'rb') as f:\n",
    "        image_data = f.read()\n",
    "    return base64.b64encode(image_data).decode('utf-8')\n",
    "\n",
    "def make_visual_cot_input_prompt(s):\n",
    "    code, output = s\n",
    "    return f\"\"\"You will be given a function `f`, its Control Flow Graph (CFG), and an output in the form `f(??) == output`. Your task is to find any input such that executing `f` on the input leads to the given output. There may be multiple answers, but only output one. First, analyze the function code and use the CFG to guide your reasoning about possible execution paths. You MUST surround the answer with [ANSWER] and [/ANSWER] tags. Express your answer as a passing assertion containing the input and the given output.\n",
    "\n",
    "[PYTHON]\n",
    "def f(x):\n",
    "    while x > 10:\n",
    "        if x % 2 == 0:\n",
    "            x -= 2\n",
    "        else:\n",
    "            x -= 4\n",
    "    return x\n",
    "    \n",
    "assert f(??) == 3\n",
    "[/PYTHON]\n",
    "\n",
    "[THOUGHT]\n",
    "To determine the input `??` such that `f(??) == 17`, we can use both the plain code and the CFG.\n",
    "\n",
    "1. **Code Analysis**: The function `f(x)` has a conditional statement that checks whether `x > 10`. If `x` is greater than 10, the function returns `x + 1`. Otherwise, it returns `x - 1`.\n",
    "  \n",
    "2. **CFG Insights**: The Control Flow Graph (CFG) illustrates two possible paths:\n",
    "   - **True Branch (`T`)**: If `x > 10`, the path leads to the operation `return x + 1`.\n",
    "   - **False Branch (`F`)**: If `x <= 10`, the path leads to the operation `return x - 1`.\n",
    "\n",
    "3. **Path Consideration**:\n",
    "   - **True Branch Analysis**: For the condition `x > 10`, the function returns `x + 1`. To satisfy `f(??) == 3`, we need `x + 1 = 17`. Solving for `x`, we get `x = 16`.\n",
    "   - **False Branch Analysis**: For the condition `x <= 10`, the function returns `x - 1`. To satisfy `f(??) == 3`, we would need `x - 1 = 17`, which gives `x = 18`. However, this contradicts the branch condition because 18 is not less than or equal to 10. Therefore, this branch cannot produce the desired output.\n",
    "\n",
    "4. **Conclusion**: Based on the CFG and the code analysis, the only valid input is `x = 16`, which lies on the True Branch.\n",
    "[/THOUGHT]\n",
    "[ANSWER]\n",
    "assert f(16) == 17\n",
    "[/ANSWER]\n",
    "\n",
    "[PYTHON]\n",
    "{code}\n",
    "assert f(??) == {output}\n",
    "[/PYTHON]\n",
    "\n",
    "[THOUGHT]\n",
    "\"\"\"\n",
    "\n",
    "def visual_run(prompt, image_data):\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        system=\"You are a helpful assistant.\",\n",
    "        messages=[\n",
    "        { \"role\": \"user\", \"content\": [  \n",
    "            { \n",
    "                \"type\": \"text\", \n",
    "                \"text\": \"You are given a control flow graph image of a code snippet, utilize them in code execution reasoning process. \" + prompt, \n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"source\": {\n",
    "                    \"type\": \"base64\",\n",
    "                    \"media_type\": \"image/png\",\n",
    "                    \"data\": image_data\n",
    "                }\n",
    "            },\n",
    "        ] }\n",
    "    ],\n",
    "        max_tokens=2048 \n",
    "    )\n",
    "\n",
    "    return response.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confi = config()\n",
    "env = CruxEnv(confi)\n",
    "for idx in tqdm(range(250)):\n",
    "    error = False\n",
    "    env.set_problem(idx)\n",
    "    print(f'Index: {idx}')\n",
    "    print(env.problem['code'])\n",
    "    print(\"_______________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confi = config()\n",
    "env = CruxEnv(confi)\n",
    "fail_case = {}\n",
    "for idx in tqdm(range(250)):\n",
    "    error = False\n",
    "    env.set_problem(idx)\n",
    "    prompt = env.get_problem_statement()\n",
    "    try:\n",
    "        solution = run(prompt) \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        error = True\n",
    "        solution = \"\"\n",
    "        time.sleep(20)\n",
    "        pass\n",
    "    correct = env.check_solution(solution)\n",
    "    if not correct:\n",
    "        print(idx)\n",
    "        fail_case[idx] = solution\n",
    "    env.accumulate_result({\"is_correct\": correct, \"solution\": solution, \"error\": error})\n",
    "env.finalize()\n",
    "print(env.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 22/250 [01:54<18:46,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 500 - {'type': 'error', 'error': {'type': 'api_error', 'message': 'Internal server error'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 229/250 [20:51<01:50,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 500 - {'type': 'error', 'error': {'type': 'api_error', 'message': 'Internal server error'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [22:43<00:00,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'correct': 196, 'total': 250, 'error': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import ast\n",
    "from cfg import * \n",
    "confi = config()\n",
    "env = CruxEnv(confi)\n",
    "false_case = {}\n",
    "for idx in tqdm(range(250)):\n",
    "    error = False\n",
    "    env.set_problem(idx)\n",
    "    prompt = env.get_problem_statement()\n",
    "    code = env.get_code()\n",
    "    # save code to file\n",
    "    filename = \"code.py\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(code)\n",
    "    try:\n",
    "        source = open(filename, 'r').read()\n",
    "        compile(source, filename, 'exec')\n",
    "    except:\n",
    "        print('Error in source code')\n",
    "        exit(1)\n",
    "\n",
    "    parser = PyParser(source)\n",
    "    parser.removeCommentsAndDocstrings()\n",
    "    parser.formatCode()\n",
    "    cfg = CFGVisitor().build(filename, ast.parse(parser.script))\n",
    "    cfg.clean()\n",
    "    cfg.show()\n",
    "    path = \"cfg.png\"\n",
    "\n",
    "    try:\n",
    "        solution = visual_run(prompt, code_to_image(code, path))\n",
    "    except Exception as e:\n",
    "        solution = \"\"\n",
    "        error = True\n",
    "        print(e)\n",
    "        pass\n",
    "    correct = env.check_solution(solution)\n",
    "    if not correct:\n",
    "        false_case[idx] = solution\n",
    "    env.accumulate_result({\"is_correct\": correct, \"solution\": solution, \"error\": error})\n",
    "env.finalize()\n",
    "print(env.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "def build_transform(input_size):\n",
    "    MEAN, STD = IMAGENET_MEAN, IMAGENET_STD\n",
    "    transform = T.Compose([\n",
    "        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
    "        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=MEAN, std=STD)\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "def find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n",
    "    best_ratio_diff = float('inf')\n",
    "    best_ratio = (1, 1)\n",
    "    area = width * height\n",
    "    for ratio in target_ratios:\n",
    "        target_aspect_ratio = ratio[0] / ratio[1]\n",
    "        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n",
    "        if ratio_diff < best_ratio_diff:\n",
    "            best_ratio_diff = ratio_diff\n",
    "            best_ratio = ratio\n",
    "        elif ratio_diff == best_ratio_diff:\n",
    "            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n",
    "                best_ratio = ratio\n",
    "    return best_ratio\n",
    "\n",
    "def dynamic_preprocess(image, min_num=1, max_num=12, image_size=448, use_thumbnail=False):\n",
    "    orig_width, orig_height = image.size\n",
    "    aspect_ratio = orig_width / orig_height\n",
    "\n",
    "    # calculate the existing image aspect ratio\n",
    "    target_ratios = set(\n",
    "        (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if\n",
    "        i * j <= max_num and i * j >= min_num)\n",
    "    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n",
    "\n",
    "    # find the closest aspect ratio to the target\n",
    "    target_aspect_ratio = find_closest_aspect_ratio(\n",
    "        aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n",
    "\n",
    "    # calculate the target width and height\n",
    "    target_width = image_size * target_aspect_ratio[0]\n",
    "    target_height = image_size * target_aspect_ratio[1]\n",
    "    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n",
    "\n",
    "    # resize the image\n",
    "    resized_img = image.resize((target_width, target_height))\n",
    "    processed_images = []\n",
    "    for i in range(blocks):\n",
    "        box = (\n",
    "            (i % (target_width // image_size)) * image_size,\n",
    "            (i // (target_width // image_size)) * image_size,\n",
    "            ((i % (target_width // image_size)) + 1) * image_size,\n",
    "            ((i // (target_width // image_size)) + 1) * image_size\n",
    "        )\n",
    "        # split the image\n",
    "        split_img = resized_img.crop(box)\n",
    "        processed_images.append(split_img)\n",
    "    assert len(processed_images) == blocks\n",
    "    if use_thumbnail and len(processed_images) != 1:\n",
    "        thumbnail_img = image.resize((image_size, image_size))\n",
    "        processed_images.append(thumbnail_img)\n",
    "    return processed_images\n",
    "\n",
    "def load_image(image_file, input_size=448, max_num=12):\n",
    "    image = Image.open(image_file).convert('RGB')\n",
    "    transform = build_transform(input_size=input_size)\n",
    "    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
    "    pixel_values = [transform(image) for image in images]\n",
    "    pixel_values = torch.stack(pixel_values)\n",
    "    return pixel_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpenGVLab/InternVL2-8B\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_flash_attn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39meval()\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      8\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(path, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, use_fast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m generation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/VLM/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:559\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mregister(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, model_class, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n",
      "File \u001b[0;32m~/miniconda3/envs/VLM/lib/python3.10/site-packages/transformers/modeling_utils.py:3318\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3314\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3315\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3316\u001b[0m         )\n\u001b[1;32m   3317\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[0;32m-> 3318\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   3319\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3320\u001b[0m         )\n\u001b[1;32m   3322\u001b[0m \u001b[38;5;66;03m# handling bnb config from kwargs, remove after `load_in_{4/8}bit` deprecation.\u001b[39;00m\n\u001b[1;32m   3323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit \u001b[38;5;129;01mor\u001b[39;00m load_in_8bit:\n",
      "\u001b[0;31mImportError\u001b[0m: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`"
     ]
    }
   ],
   "source": [
    "path = 'OpenGVLab/InternVL2-8B'\n",
    "model = AutoModel.from_pretrained(\n",
    "    path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_flash_attn=True,\n",
    "    trust_remote_code=True).eval().cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True, use_fast=False)\n",
    "generation_config = dict(max_new_tokens=1024, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_model(prompt):\n",
    "    response, history = model.chat(tokenizer, None, prompt, generation_config, history=None, return_history=True)\n",
    "    return response\n",
    "\n",
    "def code_to_image(code: str, name=\"ControlFlowGraph\"):\n",
    "    #TODO: quick fix for now, since although the cfg image is saved, the CFGBuilder is not able to finished\n",
    "    cfg = CFGBuilder().build_from_src(name, code)\n",
    "    render = cfg.build_visual(name, 'jpeg', show=False)\n",
    "    return f\"{name}.jpeg\"\n",
    "\n",
    "# def visual_run_model(prompt, image_path):\n",
    "#     pixel_values = load_image(image_path, max_num=12).to(torch.bfloat16).cuda()\n",
    "#     prompt = \"You are given a control flow graph image of a code snippet, utilize them in code execution reasoning process: <image>. Describe the image\"\n",
    "#     return model.chat(tokenizer, pixel_values, prompt, generation_config)\n",
    "\n",
    "def visual_run_model(prompt, image_path):\n",
    "    pixel_values = load_image(image_path, max_num=12).to(torch.bfloat16).cuda()\n",
    "    prompt = f\"CFG image: <image> {prompt}\"\n",
    "    return model.chat(tokenizer, pixel_values, prompt, generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = config()\n",
    "env = CruxEnv(cfg)\n",
    "for idx in tqdm(range(250)):\n",
    "    error = False\n",
    "    env.set_problem(idx)\n",
    "    prompt = env.get_problem_statement()\n",
    "    try:\n",
    "        solution = run_model(prompt)\n",
    "    except:\n",
    "        error = True\n",
    "        solution = \"\"\n",
    "        pass\n",
    "    correct = env.check_solution(solution)\n",
    "    env.accumulate_result({\"is_correct\": correct, \"solution\": solution, \"error\": error})\n",
    "env.finalize()\n",
    "print(env.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_visual_cot_output_prompt(s):\n",
    "    code, input = s\n",
    "    return f\"\"\"You are given a Python function and an assertion containing an input to the function. Complete the assertion with a literal (no unsimplified expressions, no function calls) containing the output when executing the provided code on the given input, even if the function is incorrect or incomplete. Do NOT output any extra information. Execute the program step by step before arriving at an answer, and provide the full assertion with the correct output in [ANSWER] and [/ANSWER] tags, following the examples.\n",
    "\n",
    "[PYTHON]\n",
    "def f(L, m, start, step): \n",
    "    L.insert(start, m) \n",
    "    for x in range(start-1, 0, -step): \n",
    "        start -= 1\n",
    "        L.insert(start, L.pop(L.index(m)-1)) \n",
    "    return L\n",
    "assert f(thigh_o_two[:], 3, 3, 2) == ??\n",
    "[/PYTHON]\n",
    "[THOUGHT]\n",
    "Let's execute code step by step:\n",
    "1. Initial State:\n",
    "\tL = [1, 2, 7, 9]\n",
    "\tm = 3\n",
    "\tstart = 3\n",
    "\tstep = 2\n",
    "2. First Operation (L.insert(start, m)):\n",
    "\tThis is shown in the control flow graph as the first action after the function begins.\n",
    "\tInsert m (which is 3) at index start (which is 3).\n",
    "\tL = [1, 2, 7, 3, 9]\n",
    "3. For Loop Initialization (for x in range(start - 1, 0, -step)):\n",
    "\trange(start - 1, 0, -step) becomes range(2, 0, -2) because start is 3.\n",
    "\tThe loop will iterate with x taking values 2.\n",
    "\tThe control flow graph indicates this loop.\n",
    "4. First Loop Iteration (x = 2):\n",
    "\tDecrement start by 1: start = start - 1 = 2.\n",
    "\tL.pop(L.index(m) - 1):\n",
    "\tL.index(m) finds the index of m (which is 3) in L. The index of 3 is 3.\n",
    "\tL.index(m) - 1 is 3 - 1 = 2.\n",
    "\tL.pop(2) removes and returns the element at index 2, which is 7.\n",
    "\tL.insert(start, 7):\n",
    "\tInsert 7 at index start (which is 2).\n",
    "\tL becomes [1, 2, 7, 3, 9] after removing 7 and inserting it back at the same position. (No visible change)\n",
    "5. End of Loop:\n",
    "\tThe range range(2, 0, -2) has no more values after x = 2, so the loop ends.\n",
    "\n",
    "After following the control flow of the function and given input parameters, the final output is: [1, 2, 7, 3, 9]\n",
    "[/THOUGHT]\n",
    "[ANSWER]\n",
    "f(thigh_o_two[:], 3, 3, 2) == [1, 2, 7, 3, 9]\n",
    "[/ANSWER]\n",
    "\n",
    "[PYTHON]\n",
    "{code}\n",
    "assert f({input}) == ??\n",
    "[/PYTHON]\n",
    "[THOUGHT]\n",
    "\"\"\"\n",
    "\n",
    "def make_visual_cot_input_prompt(s):\n",
    "    code, output = s\n",
    "    return f\"\"\"You are given a Python function and an assertion containing an input to the function. Complete the assertion with a literal (no unsimplified expressions, no function calls) containing the output when executing the provided code on the given input, even if the function is incorrect or incomplete. Do NOT output any extra information. Execute the program step by step before arriving at an answer, and provide the full assertion with the correct output in [ANSWER] and [/ANSWER] tags, following the examples.\n",
    "\n",
    "[[PYTHON]\n",
    "def f(num):\n",
    "    for i in range(10):\n",
    "        if num % 2 == 0:\n",
    "            num -= 2*i\n",
    "        else:\n",
    "            num += 2*i\n",
    "    if num % 3 == 0:\n",
    "        num -= 3\n",
    "    elif num % 3 == 1:\n",
    "        num += 6\n",
    "    else:\n",
    "        num += 3\n",
    "    return num\n",
    "\n",
    "assert f(??) == 103\n",
    "[/PYTHON]\n",
    "\n",
    "[THOUGHT]\n",
    "Let's execute the code step by step:\n",
    "\n",
    "1. The function `f` is defined, which takes a single argument `num`.\n",
    "2. The function is called with an initial value for `num`, which we need to determine.\n",
    "3. Inside the function, there is a loop that runs 10 times (`for i in range(10)`). During each iteration:\n",
    "   - If `num` is even, it is decreased by `2 * i`.\n",
    "   - If `num` is odd, it is increased by `2 * i`.\n",
    "4. After the loop, there are three conditional checks based on the value of `num % 3`:\n",
    "   - If `num % 3 == 0`, 3 is subtracted from `num`.\n",
    "   - If `num % 3 == 1`, 6 is added to `num`.\n",
    "   - Otherwise, 3 is added to `num`.\n",
    "5. The goal is to find the initial value of `num` such that the function returns 103 after all operations.\n",
    "\n",
    "Let's think backward using the CFG:\n",
    "\n",
    "1. If the function returns 103, we follow the path in the CFG. We notice that the final operation performed was adding 6 to `num` (since `num % 3 == 1`).\n",
    "   - Therefore, the value of `num` before the final `if` statement must have been `103 - 6 = 97`.\n",
    "   \n",
    "2. The loop operations involve adding or subtracting `2 * i` based on whether `num` is even or odd. Importantly, these operations do not affect whether `num % 3` equals 1 (the remainder remains consistent under the transformations).\n",
    "\n",
    "3. Similarly, the loop preserves the property of whether `num` is even or odd due to the alternating addition and subtraction by even amounts. Thus, we need to determine a starting value of `num` such that it reaches 97 after the loop operations.\n",
    "\n",
    "4. By analyzing the sequence of operations, we determine that starting with `num = 7` and following through all iterations of the loop, the value transitions correctly to meet all conditions and ultimately results in 103.\n",
    "\n",
    "Therefore, the correct input that produces 103 is 7.\n",
    "[/THOUGHT]\n",
    "[ANSWER]\n",
    "assert f(7) == 103\n",
    "[/ANSWER]\n",
    "\n",
    "[PYTHON]\n",
    "{code}\n",
    "assert f(??) == {output}\n",
    "[/PYTHON]\n",
    "[THOUGHT]\n",
    "\"\"\"\n",
    "\n",
    "cfg = config()\n",
    "env = CruxEnv(cfg)\n",
    "for idx in tqdm(range(250)):\n",
    "    error = False\n",
    "    env.set_problem(idx)\n",
    "    # prompt = env.get_problem_statement()\n",
    "    prompt = env.get_problem_statement(make_visual_cot_output_prompt)\n",
    "    code = env.get_code()\n",
    "    try:\n",
    "        solution = visual_run_model(prompt, code_to_image(code))\n",
    "    except Exception as e:\n",
    "        solution = \"\"\n",
    "        error = True\n",
    "        print(e)\n",
    "        pass\n",
    "    correct = env.check_solution(solution)\n",
    "    env.accumulate_result({\"is_correct\": correct, \"solution\": solution, \"error\": error})\n",
    "env.finalize()\n",
    "print(env.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'correct': 104, 'total': 250, 'error': 2}\n"
     ]
    }
   ],
   "source": [
    "print(env.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini \n",
    "import google.generativeai as genai \n",
    "import PIL.Image \n",
    "import os  \n",
    "genai.configure(api_key=\"AIzaSyBUShLYTXK4agg-o-03R3iSrmq9BGcm_34\") \n",
    "img = PIL.Image.open('ControlFlowGraph.jpeg')  \n",
    "client = genai.GenerativeModel(model_name=\"gemini-1.5-flash\") \n",
    "\n",
    "one_shot_code = \"\"\"def f(L, m, start, step): \n",
    "    L.insert(start, m) \n",
    "    for x in range(start-1, 0, -step): \n",
    "        start -= 1\n",
    "        L.insert(start, L.pop(L.index(m)-1)) \n",
    "    return L\"\"\"\n",
    "\n",
    "def run_gemini(prompt):\n",
    "    return client.generate_content([prompt]).text\n",
    "\n",
    "def visual_run_gemini(prompt, image_path):\n",
    "    img = PIL.Image.open(image_path)\n",
    "    img1 = PIL.Image.open('cfg_example.png')\n",
    "    prompt = \"You are given a control flow graph image of a code snippet, utilize them in code execution reasoning process. \" + prompt\n",
    "    return client.generate_content([img1, img, prompt]).text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "cfg = config()\n",
    "env = CruxEnv(cfg)\n",
    "for idx in tqdm(range(250)):\n",
    "    error = False\n",
    "    env.set_problem(idx)\n",
    "    prompt = env.get_problem_statement()\n",
    "    \n",
    "    # Initialize variables\n",
    "    attempts = 0\n",
    "    max_attempts = 5\n",
    "    while attempts < max_attempts:\n",
    "        try:\n",
    "            solution = run_gemini(prompt)\n",
    "            break \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            error = True\n",
    "            attempts += 1  # Increment the attempts counter\n",
    "            if attempts < max_attempts:\n",
    "                time.sleep(60)  \n",
    "            else:\n",
    "                solution = \"\"  \n",
    "                print(\"Failed after 4 attempts\")\n",
    "                break \n",
    "    correct = env.check_solution(solution)\n",
    "    env.accumulate_result({\"is_correct\": correct, \"solution\": solution, \"error\": error})\n",
    "env.finalize()\n",
    "print(env.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'correct': 146, 'total': 250, 'error': 12}\n"
     ]
    }
   ],
   "source": [
    "print(env.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 31/250 [01:47<10:46,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 50/250 [03:52<09:11,  2.76s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 85/250 [06:59<09:33,  3.48s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 101/250 [08:46<06:07,  2.46s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 249/250 [22:57<00:02,  2.64s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [24:05<00:00,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'correct': 58, 'total': 250, 'error': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import time \n",
    "import ast\n",
    "from cfg import * \n",
    "\n",
    "def make_visual_cot_output_prompt(s):\n",
    "    code, input = s\n",
    "    return f\"\"\"You are given a Python function and an assertion containing an input to the function. Complete the assertion with a literal (no unsimplified expressions, no function calls) containing the output when executing the provided code on the given input, even if the function is incorrect or incomplete. Do NOT output any extra information. Execute the program step by step before arriving at an answer, and provide the full assertion with the correct output in [ANSWER] and [/ANSWER] tags, following the examples.\n",
    "\n",
    "[PYTHON]\n",
    "def f(L, m, start, step): \n",
    "    L.insert(start, m) \n",
    "    for x in range(start-1, 0, -step): \n",
    "        start -= 1\n",
    "        L.insert(start, L.pop(L.index(m)-1)) \n",
    "    return L\n",
    "assert f(thigh_o_two[:], 3, 3, 2) == ??\n",
    "[/PYTHON]\n",
    "[THOUGHT]\n",
    "Let's execute code step by step:\n",
    "1. Initial State:\n",
    "\tL = [1, 2, 7, 9]\n",
    "\tm = 3\n",
    "\tstart = 3\n",
    "\tstep = 2\n",
    "2. First Operation (L.insert(start, m)):\n",
    "\tThis is shown in the control flow graph as the first action after the function begins.\n",
    "\tInsert m (which is 3) at index start (which is 3).\n",
    "\tL = [1, 2, 7, 3, 9]\n",
    "3. For Loop Initialization (for x in range(start - 1, 0, -step)):\n",
    "\trange(start - 1, 0, -step) becomes range(2, 0, -2) because start is 3.\n",
    "\tThe loop will iterate with x taking values 2.\n",
    "\tThe control flow graph indicates this loop.\n",
    "4. First Loop Iteration (x = 2):\n",
    "\tDecrement start by 1: start = start - 1 = 2.\n",
    "\tL.pop(L.index(m) - 1):\n",
    "\tL.index(m) finds the index of m (which is 3) in L. The index of 3 is 3.\n",
    "\tL.index(m) - 1 is 3 - 1 = 2.\n",
    "\tL.pop(2) removes and returns the element at index 2, which is 7.\n",
    "\tL.insert(start, 7):\n",
    "\tInsert 7 at index start (which is 2).\n",
    "\tL becomes [1, 2, 7, 3, 9] after removing 7 and inserting it back at the same position. (No visible change)\n",
    "5. End of Loop:\n",
    "\tThe range range(2, 0, -2) has no more values after x = 2, so the loop ends.\n",
    "\n",
    "After following the control flow of the function and given input parameters, the final output is: [1, 2, 7, 3, 9]\n",
    "[/THOUGHT]\n",
    "[ANSWER]\n",
    "f(thigh_o_two[:], 3, 3, 2) == [1, 2, 7, 3, 9]\n",
    "[/ANSWER]\n",
    "\n",
    "[PYTHON]\n",
    "{code}\n",
    "assert f({input}) == ??\n",
    "[/PYTHON]\n",
    "[THOUGHT]\n",
    "\"\"\"\n",
    "\n",
    "confi = config()\n",
    "env = CruxEnv(confi)\n",
    "for idx in tqdm(range(250)):\n",
    "    error = False\n",
    "    env.set_problem(idx)\n",
    "    prompt = env.get_problem_statement(make_visual_cot_output_prompt)\n",
    "    code = env.get_code()\n",
    "    \n",
    "    # Initialize variables\n",
    "    attempts = 0\n",
    "    max_attempts = 5\n",
    "    filename = \"code.py\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(code)\n",
    "    try:\n",
    "        source = open(filename, 'r').read()\n",
    "        compile(source, filename, 'exec')\n",
    "    except:\n",
    "        print('Error in source code')\n",
    "        exit(1)\n",
    "\n",
    "    parser = PyParser(source)\n",
    "    parser.removeCommentsAndDocstrings()\n",
    "    parser.formatCode()\n",
    "    cfg = CFGVisitor().build(filename, ast.parse(parser.script))\n",
    "    cfg.clean()\n",
    "    cfg.show()\n",
    "    path = \"cfg.png\"\n",
    "    \n",
    "    while attempts < max_attempts:\n",
    "        try:\n",
    "            solution = visual_run_gemini(prompt, path)\n",
    "            break \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            error = True\n",
    "            attempts += 1  # Increment the attempts counter\n",
    "            if attempts < max_attempts:\n",
    "                time.sleep(60)  \n",
    "            else:\n",
    "                solution = \"\"  \n",
    "                print(\"Failed after 4 attempts\")\n",
    "                break \n",
    "    correct = env.check_solution(solution)\n",
    "    env.accumulate_result({\"is_correct\": correct, \"solution\": solution, \"error\": error})\n",
    "env.finalize()\n",
    "print(env.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'correct': 171, 'total': 250, 'error': 5}\n"
     ]
    }
   ],
   "source": [
    "print(env.result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repopilot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
